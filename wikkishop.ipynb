{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Загрузим-библиотеки\" data-toc-modified-id=\"Загрузим-библиотеки-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>Загрузим библиотеки</a></span></li><li><span><a href=\"#Загружаем-данные\" data-toc-modified-id=\"Загружаем-данные-1.0.2\"><span class=\"toc-item-num\">1.0.2&nbsp;&nbsp;</span>Загружаем данные</a></span></li><li><span><a href=\"#Изучаем-данные\" data-toc-modified-id=\"Изучаем-данные-1.0.3\"><span class=\"toc-item-num\">1.0.3&nbsp;&nbsp;</span>Изучаем данные</a></span></li><li><span><a href=\"#Изучим-столбец-с-целевым-признаком\" data-toc-modified-id=\"Изучим-столбец-с-целевым-признаком-1.0.4\"><span class=\"toc-item-num\">1.0.4&nbsp;&nbsp;</span>Изучим столбец с целевым признаком</a></span></li><li><span><a href=\"#Вывод:\" data-toc-modified-id=\"Вывод:-1.0.5\"><span class=\"toc-item-num\">1.0.5&nbsp;&nbsp;</span>Вывод:</a></span></li><li><span><a href=\"#Токенизируем-и-лемматизируем-столбец-text-и-добавим-данные-в-столбец-text_final\" data-toc-modified-id=\"Токенизируем-и-лемматизируем-столбец-text-и-добавим-данные-в-столбец-text_final-1.0.6\"><span class=\"toc-item-num\">1.0.6&nbsp;&nbsp;</span>Токенизируем и лемматизируем столбец text и добавим данные в столбец text_final</a></span></li><li><span><a href=\"#Выведем-одну-строку-для-последующего-контроля\" data-toc-modified-id=\"Выведем-одну-строку-для-последующего-контроля-1.0.7\"><span class=\"toc-item-num\">1.0.7&nbsp;&nbsp;</span>Выведем одну строку для последующего контроля</a></span></li><li><span><a href=\"#Запускаем-преобразование-с-контролем-времени-работы\" data-toc-modified-id=\"Запускаем-преобразование-с-контролем-времени-работы-1.0.8\"><span class=\"toc-item-num\">1.0.8&nbsp;&nbsp;</span>Запускаем преобразование с контролем времени работы</a></span></li><li><span><a href=\"#Проверим-преобразование\" data-toc-modified-id=\"Проверим-преобразование-1.0.9\"><span class=\"toc-item-num\">1.0.9&nbsp;&nbsp;</span>Проверим преобразование</a></span></li><li><span><a href=\"#Создадим-признаки-и-целевой-признак\" data-toc-modified-id=\"Создадим-признаки-и-целевой-признак-1.0.10\"><span class=\"toc-item-num\">1.0.10&nbsp;&nbsp;</span>Создадим признаки и целевой признак</a></span></li><li><span><a href=\"#Разобъем-на-выборки-тренировочную-и-тестовую\" data-toc-modified-id=\"Разобъем-на-выборки-тренировочную-и-тестовую-1.0.11\"><span class=\"toc-item-num\">1.0.11&nbsp;&nbsp;</span>Разобъем на выборки тренировочную и тестовую</a></span></li><li><span><a href=\"#Проверим-распределения-классов-в-выборках\" data-toc-modified-id=\"Проверим-распределения-классов-в-выборках-1.0.12\"><span class=\"toc-item-num\">1.0.12&nbsp;&nbsp;</span>Проверим распределения классов в выборках</a></span></li><li><span><a href=\"#Создадим-корпус\" data-toc-modified-id=\"Создадим-корпус-1.0.13\"><span class=\"toc-item-num\">1.0.13&nbsp;&nbsp;</span>Создадим корпус</a></span></li><li><span><a href=\"#Укажем-стоп-слова\" data-toc-modified-id=\"Укажем-стоп-слова-1.0.14\"><span class=\"toc-item-num\">1.0.14&nbsp;&nbsp;</span>Укажем стоп-слова</a></span></li><li><span><a href=\"#Векторизируем-наши-признаки-с-учетом-стоп-слов\" data-toc-modified-id=\"Векторизируем-наши-признаки-с-учетом-стоп-слов-1.0.15\"><span class=\"toc-item-num\">1.0.15&nbsp;&nbsp;</span>Векторизируем наши признаки с учетом стоп-слов</a></span><ul class=\"toc-item\"><li><span><a href=\"#TF-IDF\" data-toc-modified-id=\"TF-IDF-1.0.15.1\"><span class=\"toc-item-num\">1.0.15.1&nbsp;&nbsp;</span>TF-IDF</a></span></li></ul></li><li><span><a href=\"#Проверим-данные-после-векторизации\" data-toc-modified-id=\"Проверим-данные-после-векторизации-1.0.16\"><span class=\"toc-item-num\">1.0.16&nbsp;&nbsp;</span>Проверим данные после векторизации</a></span></li><li><span><a href=\"#Вывод:\" data-toc-modified-id=\"Вывод:-1.0.17\"><span class=\"toc-item-num\">1.0.17&nbsp;&nbsp;</span>Вывод:</a></span></li></ul></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Обучим-следующие-модели:\" data-toc-modified-id=\"Обучим-следующие-модели:-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span>Обучим следующие модели:</a></span></li><li><span><a href=\"#Обучим-LogisticRegression-и-вычислим-F1-score-TF-IDF\" data-toc-modified-id=\"Обучим-LogisticRegression-и-вычислим-F1-score-TF-IDF-2.0.2\"><span class=\"toc-item-num\">2.0.2&nbsp;&nbsp;</span>Обучим LogisticRegression и вычислим F1-score TF-IDF</a></span></li><li><span><a href=\"#Внесем-данные-в-таблицу-results\" data-toc-modified-id=\"Внесем-данные-в-таблицу-results-2.0.3\"><span class=\"toc-item-num\">2.0.3&nbsp;&nbsp;</span>Внесем данные в таблицу results</a></span></li><li><span><a href=\"#Обучим-RandomForestClassifier-и--вычислим-F1-score-TF-IDF\" data-toc-modified-id=\"Обучим-RandomForestClassifier-и--вычислим-F1-score-TF-IDF-2.0.4\"><span class=\"toc-item-num\">2.0.4&nbsp;&nbsp;</span>Обучим RandomForestClassifier и  вычислим F1-score TF-IDF</a></span></li><li><span><a href=\"#Обучим-DecisionTreeClassifier-и-вычислим-F1-score-TF-IDF\" data-toc-modified-id=\"Обучим-DecisionTreeClassifier-и-вычислим-F1-score-TF-IDF-2.0.5\"><span class=\"toc-item-num\">2.0.5&nbsp;&nbsp;</span>Обучим DecisionTreeClassifier и вычислим F1-score TF-IDF</a></span></li></ul></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузим библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# from pymystem3 import Mystem\n",
    "m = WordNetLemmatizer() \n",
    "import re\n",
    "from tqdm import notebook\n",
    "notebook.tqdm.pandas() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Изучаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.head())\n",
    "display(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Изучим столбец с целевым признаком"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    89.83%\n",
       "1    10.17%\n",
       "Name: toxic, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(data['toxic'].value_counts())\n",
    "data['toxic'].value_counts(normalize=True).map('{:.2%}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод:\n",
    "* Данные загружены, состоят из 159571 строк и 2 столбцов\n",
    "* Столбец toxic является целевым признаком с выраженым дисбалансом классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Токенизируем и лемматизируем столбец text и добавим данные в столбец text_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_tokenize(text):\n",
    "    tokenized = nltk.word_tokenize(text)\n",
    "    joined = ' '.join(tokenized)\n",
    "    text_only = re.sub(r'[^a-zA-Z]', ' ', joined)\n",
    "    final = ' '.join(text_only.split())\n",
    "    x =  \"\".join(m.lemmatize(final))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выведем одну строку для последующего контроля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Запускаем преобразование с контролем времени работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c62b8108f7b4befa8f99c571946fa8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=159571.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "notebook.tqdm.pandas() \n",
    "data['text_final'] = data['text'].progress_apply(text_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверим преобразование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explanation Why the edits made under my username Hardcore Metallica Fan were reverted They were n t vandalisms just closure on some GAs after I voted at New York Dolls FAC And please do n t remove the template from the talk page since I m retired now'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data['text_final'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создадим признаки и целевой признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data['text_final']\n",
    "target = data['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разобъем на выборки тренировочную и тестовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119678,)\n",
      "(119678,)\n",
      "(39893,)\n",
      "(39893,)\n"
     ]
    }
   ],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, random_state=12345, \n",
    "                                                                            stratify=target)\n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверим распределения классов в выборках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение классов в обучающей выборке:\n",
      "0.8983188221728304\n",
      "0.10168117782716957\n",
      "\n",
      "Распределение классов в тестовой выборке:\n",
      "0.8983280274734916\n",
      "0.1016719725265084\n"
     ]
    }
   ],
   "source": [
    "print('Распределение классов в обучающей выборке:')\n",
    "print(target_train.value_counts()[0] / target_train.value_counts().sum())\n",
    "print(target_train.value_counts()[1] / target_train.value_counts().sum())\n",
    "print()\n",
    "print('Распределение классов в тестовой выборке:')\n",
    "print(target_test.value_counts()[0] / target_test.value_counts().sum())\n",
    "print(target_test.value_counts()[1] / target_test.value_counts().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создадим корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train = features_train.values.astype('U')\n",
    "corpus_test = features_test.values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Укажем стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "display(len(stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Векторизируем наши признаки с учетом стоп-слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.8 s, sys: 113 ms, total: 12.9 s\n",
      "Wall time: 13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features_train_data_tf_idf = tf_idf.fit_transform(corpus_train)\n",
    "features_test_data_tf_idf = tf_idf.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверим данные после векторизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF train\n",
      "(119678, 142074)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "TF-IDF test\n",
      "(39893, 142074)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('TF-IDF train')\n",
    "print(features_train_data_tf_idf.shape)\n",
    "print(features_train_data_tf_idf[:5].toarray())\n",
    "print()\n",
    "print('TF-IDF test')\n",
    "print(features_test_data_tf_idf.shape)\n",
    "print(features_test_data_tf_idf[:5].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод:\n",
    "* Токенизировали и лемматизировали столбец text и добавили данные в столбец text_final\n",
    "* Провели оценку важности слов определением величины TF-IDF\n",
    "* Проверили данные после векторизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучим следующие модели:\n",
    "* LogisticRegression\n",
    "* RandomForestClassifier\n",
    "* DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучим LogisticRegression и вычислим F1-score TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.3 s, sys: 4.79 s, total: 12.1 s\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(max_iter=500, random_state=12345, class_weight='balanced')\n",
    "model.fit(features_train_data_tf_idf, target_train)\n",
    "predictions = model.predict(features_test_data_tf_idf)\n",
    "    \n",
    "test_f1_score = f1_score(target_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Внесем данные в таблицу results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'Preprocessing model' : ['TF-IDF'],\n",
    "                        'Learning model' : ['LogisticRegression'], \n",
    "                        'Test f1 score' : round(test_f1_score, 2)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучим RandomForestClassifier и  вычислим F1-score TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 0 ns, total: 1min 9s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = RandomForestClassifier(random_state=12345, class_weight = 'balanced')\n",
    "model.fit(features_train_data_tf_idf, target_train)\n",
    "predictions = model.predict(features_test_data_tf_idf)\n",
    "    \n",
    "test_f1_score = f1_score(target_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append({'Preprocessing model' : 'TF-IDF',\n",
    "                        'Learning model' : 'RandomForestClassifier', \n",
    "                          'Test f1 score' : round(test_f1_score, 2)}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучим DecisionTreeClassifier и вычислим F1-score TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 4s, sys: 2.48 ms, total: 3min 4s\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = DecisionTreeClassifier(random_state=12345, class_weight = 'balanced')\n",
    "model.fit(features_train_data_tf_idf, target_train)\n",
    "predictions = model.predict(features_test_data_tf_idf)\n",
    "    \n",
    "test_f1_score = f1_score(target_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append({'Preprocessing model' : 'TF-IDF',\n",
    "                        'Learning model' : 'DecisionTreeClassifier',\n",
    "                          'Test f1 score' : round(test_f1_score, 2)}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessing model</th>\n",
       "      <th>Learning model</th>\n",
       "      <th>Test f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Preprocessing model          Learning model  Test f1 score\n",
       "0              TF-IDF      LogisticRegression           0.76\n",
       "1              TF-IDF  RandomForestClassifier           0.59\n",
       "2              TF-IDF  DecisionTreeClassifier           0.66"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Данные загружены, состоят из 159571 строк и 2 столбцов\n",
    "* Столбец toxic является целевым признаком с выраженым дисбалансом классов\n",
    "* Токенизировали и лемматизировали столбец text и добавим данные в столбец text_final\n",
    "* Провели оценку важности слов определением величины TF-IDF\n",
    "* Проверили данные после векторизации\n",
    "* Обучили следующие модели:\n",
    "   * LogisticRegression\n",
    "   * RandomForestClassifier\n",
    "   * DecisionTreeClassifier\n",
    "* Лучший результат метрики F1-score **0.76** показала модель LogisticRegression\n",
    "* Другие модели не прошли по условию **F1-score не меньше 0.75** и время обучения и предсказания намного выше чем у модели LogisticRegression\n",
    "* Модель **LogisticRegression** можно рекомендовать для использования в качестве инструмента, который будет искать токсичные комментарии и отправлять их на модерацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
